{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7360152,"sourceType":"datasetVersion","datasetId":4275145}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchtext==0.16.0","metadata":{"execution":{"iopub.status.busy":"2024-09-19T12:39:52.125310Z","iopub.execute_input":"2024-09-19T12:39:52.125753Z","iopub.status.idle":"2024-09-19T12:42:03.514347Z","shell.execute_reply.started":"2024-09-19T12:39:52.125714Z","shell.execute_reply":"2024-09-19T12:42:03.513344Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torchtext==0.16.0\n  Downloading torchtext-0.16.0-cp310-cp310-manylinux1_x86_64.whl.metadata (7.5 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torchtext==0.16.0) (4.66.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchtext==0.16.0) (2.32.3)\nCollecting torch==2.1.0 (from torchtext==0.16.0)\n  Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchtext==0.16.0) (1.26.4)\nCollecting torchdata==0.7.0 (from torchtext==0.16.0)\n  Downloading torchdata-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchtext==0.16.0) (3.15.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchtext==0.16.0) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchtext==0.16.0) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchtext==0.16.0) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchtext==0.16.0) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchtext==0.16.0) (2024.6.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.0->torchtext==0.16.0)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.0->torchtext==0.16.0)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.0->torchtext==0.16.0)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.0->torchtext==0.16.0)\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.0->torchtext==0.16.0)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.0->torchtext==0.16.0)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.0->torchtext==0.16.0)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.0->torchtext==0.16.0)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.0->torchtext==0.16.0)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.0->torchtext==0.16.0)\n  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.0->torchtext==0.16.0)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.1.0 (from torch==2.1.0->torchtext==0.16.0)\n  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\nRequirement already satisfied: urllib3>=1.25 in /opt/conda/lib/python3.10/site-packages (from torchdata==0.7.0->torchtext==0.16.0) (1.26.18)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0->torchtext==0.16.0)\n  Downloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext==0.16.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext==0.16.0) (3.7)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext==0.16.0) (2024.7.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.1.0->torchtext==0.16.0) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.1.0->torchtext==0.16.0) (1.3.0)\nDownloading torchtext-0.16.0-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchdata-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchdata, torchtext\n  Attempting uninstall: torch\n    Found existing installation: torch 2.4.0\n    Uninstalling torch-2.4.0:\n      Successfully uninstalled torch-2.4.0\nSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.6.68 nvidia-nvtx-cu12-12.1.105 torch-2.1.0 torchdata-0.7.0 torchtext-0.16.0 triton-2.1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install timm","metadata":{"execution":{"iopub.status.busy":"2024-09-19T12:44:26.602799Z","iopub.execute_input":"2024-09-19T12:44:26.603562Z","iopub.status.idle":"2024-09-19T12:44:39.626120Z","shell.execute_reply.started":"2024-09-19T12:44:26.603524Z","shell.execute_reply":"2024-09-19T12:44:39.624818Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (1.0.8)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from timm) (2.1.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.19.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0.2)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.24.6)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->timm) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.1.4)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (2.18.1)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (12.1.105)\nRequirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (2.1.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->timm) (12.6.68)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub->timm) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->timm) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->timm) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install torchvision==0.16.0","metadata":{"execution":{"iopub.status.busy":"2024-09-19T12:50:38.990536Z","iopub.execute_input":"2024-09-19T12:50:38.990935Z","iopub.status.idle":"2024-09-19T12:50:53.509502Z","shell.execute_reply.started":"2024-09-19T12:50:38.990899Z","shell.execute_reply":"2024-09-19T12:50:53.508298Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting torchvision==0.16.0\n  Downloading torchvision-0.16.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision==0.16.0) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision==0.16.0) (2.32.3)\nRequirement already satisfied: torch==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.16.0) (2.1.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.16.0) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchvision==0.16.0) (3.15.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchvision==0.16.0) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchvision==0.16.0) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchvision==0.16.0) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchvision==0.16.0) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchvision==0.16.0) (2024.6.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchvision==0.16.0) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchvision==0.16.0) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchvision==0.16.0) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchvision==0.16.0) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchvision==0.16.0) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchvision==0.16.0) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchvision==0.16.0) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchvision==0.16.0) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchvision==0.16.0) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchvision==0.16.0) (2.18.1)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchvision==0.16.0) (12.1.105)\nRequirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchvision==0.16.0) (2.1.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0->torchvision==0.16.0) (12.6.68)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.16.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.16.0) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.16.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.16.0) (2024.7.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.1.0->torchvision==0.16.0) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.1.0->torchvision==0.16.0) (1.3.0)\nDownloading torchvision-0.16.0-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torchvision\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.19.0\n    Uninstalling torchvision-0.19.0:\n      Successfully uninstalled torchvision-0.19.0\nSuccessfully installed torchvision-0.16.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchtext\nimport os\nimport numpy as np\nimport pandas as pd\nimport spacy\nimport timm\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom torchtext.data.utils import get_tokenizer\nfrom torchtext.vocab import build_vocab_from_iterator\nfrom torchvision import transforms\nfrom transformers import ViTModel, ViTImageProcessor\nfrom transformers import AutoTokenizer, RobertaModel","metadata":{"execution":{"iopub.status.busy":"2024-09-19T12:51:08.000664Z","iopub.execute_input":"2024-09-19T12:51:08.001312Z","iopub.status.idle":"2024-09-19T12:51:08.202933Z","shell.execute_reply.started":"2024-09-19T12:51:08.001272Z","shell.execute_reply":"2024-09-19T12:51:08.201518Z"},"trusted":true},"execution_count":7,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtimm\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/timm/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_scriptable, is_exportable, set_scriptable, set_exportable\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_model, list_models, list_pretrained, is_model, list_modules, model_entrypoint, \\\n\u001b[1;32m      4\u001b[0m     is_model_pretrained, get_pretrained_cfg, get_pretrained_cfg_value\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/timm/layers/__init__.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattention_pool2d\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AttentionPool2d, RotAttentionPool2d, RotaryEmbedding\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblur_pool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BlurPool2d, create_aa\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassifier\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClassifierHead, create_classifier, NormMlpClassifierHead\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcond_conv2d\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CondConv2d, get_condconv_initializer\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_exportable, is_scriptable, is_no_jit, use_fused_attn, \\\n\u001b[1;32m     11\u001b[0m     set_exportable, set_scriptable, set_no_jit, set_layer_config, set_fused_attn\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/timm/layers/classifier.py:15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madaptive_avgmax_pool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SelectAdaptivePool2d\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcreate_act\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_act_layer\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcreate_norm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_norm_layer\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_pool\u001b[39m(\n\u001b[1;32m     19\u001b[0m         num_features: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m     20\u001b[0m         num_classes: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m         input_fmt: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     24\u001b[0m ):\n\u001b[1;32m     25\u001b[0m     flatten_in_pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m use_conv  \u001b[38;5;66;03m# flatten when we use a Linear layer after pooling\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/timm/layers/create_norm.py:14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnorm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GroupNorm, GroupNorm1, LayerNorm, LayerNorm2d, RmsNorm\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FrozenBatchNorm2d\n\u001b[1;32m     16\u001b[0m _NORM_MAP \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m     17\u001b[0m     batchnorm\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mBatchNorm2d,\n\u001b[1;32m     18\u001b[0m     batchnorm2d\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mBatchNorm2d,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     frozenbatchnorm2d\u001b[38;5;241m=\u001b[39mFrozenBatchNorm2d,\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     27\u001b[0m _NORM_TYPES \u001b[38;5;241m=\u001b[39m {m \u001b[38;5;28;01mfor\u001b[39;00m n, m \u001b[38;5;129;01min\u001b[39;00m _NORM_MAP\u001b[38;5;241m.\u001b[39mitems()}\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/__init__.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodulefinder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Module\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/_meta_registrations.py:25\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129;43m@register_meta\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mroi_align\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mmeta_roi_align\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrois\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspatial_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooled_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooled_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maligned\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrois\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrois must have shape as Tensor[K, 5]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrois\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/_meta_registrations.py:17\u001b[0m, in \u001b[0;36mregister_meta.<locals>.wrapper\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(fn):\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextension\u001b[49m\u001b[38;5;241m.\u001b[39m_has_ops():\n\u001b[1;32m     18\u001b[0m         get_meta_lib()\u001b[38;5;241m.\u001b[39mimpl(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mtorchvision, op_name), overload_name), fn)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\n","\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)"],"ename":"AttributeError","evalue":"partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)","output_type":"error"}]},{"cell_type":"markdown","source":"# Read Dataset","metadata":{}},{"cell_type":"code","source":"train_data = []\ntrain_set_path = '/kaggle/input/vqa-aio/Data/vaq2.0.TrainImages.txt'\n\nwith open(train_set_path, \"r\") as f:\n    lines = f.readlines()\n    for line in lines:\n        temp = line.split('\\t')\n        qa = temp[1].split('?')\n\n        if len(qa) == 3:\n            answer = qa[2].strip()\n        else:\n            answer = qa[1].strip()\n\n        data_sample = {\n            'image_path': temp[0][:-2],\n            'question': qa[0] + '?',\n            'answer': answer\n        }\n        train_data.append(data_sample)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T04:13:37.800962Z","iopub.status.idle":"2024-09-19T04:13:37.801383Z","shell.execute_reply.started":"2024-09-19T04:13:37.801156Z","shell.execute_reply":"2024-09-19T04:13:37.801176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_data = []\nval_set_path = '/kaggle/input/vqa-aio/Data/vaq2.0.DevImages.txt'\n\nwith open(val_set_path, \"r\") as f:\n    lines = f.readlines()\n    for line in lines:\n        temp = line.split('\\t')\n        qa = temp[1].split('?')\n\n        if len(qa) == 3:\n            answer = qa[2].strip()\n        else:\n            answer = qa[1].strip()\n\n        data_sample = {\n            'image_path': temp[0][:-2],\n            'question': qa[0] + '?',\n            'answer': answer\n        }\n        val_data.append(data_sample)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-19T04:13:37.802467Z","iopub.status.idle":"2024-09-19T04:13:37.802876Z","shell.execute_reply.started":"2024-09-19T04:13:37.802677Z","shell.execute_reply":"2024-09-19T04:13:37.802696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# val_data","metadata":{"execution":{"iopub.status.busy":"2024-09-19T04:13:37.804605Z","iopub.status.idle":"2024-09-19T04:13:37.805003Z","shell.execute_reply.started":"2024-09-19T04:13:37.804806Z","shell.execute_reply":"2024-09-19T04:13:37.804826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = []\ntrain_set_path = '/kaggle/input/vqa-aio/Data/vaq2.0.TrainImages.txt'\n\nwith open(train_set_path, \"r\") as f:\n    lines = f.readlines()\n    for line in lines:\n        temp = line.split('\\t')\n        qa = temp[1].split('?')\n        \n        if len(qa) == 3:\n            answer = qa[2].strip()\n        else:\n            answer = qa[1].strip()\n        \n        data_sample = {\n            'image_path': temp[0][:-2],\n            'question': qa[0] + '?',\n            'answer': answer\n        }\n        train_data.append(data_sample)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T04:13:37.806207Z","iopub.status.idle":"2024-09-19T04:13:37.806628Z","shell.execute_reply.started":"2024-09-19T04:13:37.806403Z","shell.execute_reply":"2024-09-19T04:13:37.806422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = []\ntest_set_path = '/kaggle/input/vqa-aio/Data/vaq2.0.TestImages.txt'\n\nwith open(test_set_path, \"r\") as f:\n    lines = f.readlines()\n    for line in lines:\n        temp = line.split('\\t')\n        qa = temp[1].split('?')\n        \n        if len(qa) == 3:\n            answer = qa[2].strip()\n        else:\n            answer = qa[1].strip()\n        \n        data_sample = {\n            'image_path': temp[0][:-2],\n            'question': qa[0] + '?',\n            'answer': answer\n        }\n        test_data.append(data_sample)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T04:13:37.808422Z","iopub.status.idle":"2024-09-19T04:13:37.808928Z","shell.execute_reply.started":"2024-09-19T04:13:37.808667Z","shell.execute_reply":"2024-09-19T04:13:37.808692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_data","metadata":{"execution":{"iopub.status.busy":"2024-09-19T04:13:37.810117Z","iopub.status.idle":"2024-09-19T04:13:37.810584Z","shell.execute_reply.started":"2024-09-19T04:13:37.810325Z","shell.execute_reply":"2024-09-19T04:13:37.810353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = set([sample['answer'] for sample in train_data])\nclasses_to_idx = {\n    cls_name: idx for idx, cls_name in enumerate(classes)\n}\nidx_to_classes = {\n    idx: cls_name for idx, cls_name in enumerate(classes)\n}\nprint(idx_to_classes)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T04:13:37.811894Z","iopub.status.idle":"2024-09-19T04:13:37.812243Z","shell.execute_reply.started":"2024-09-19T04:13:37.812066Z","shell.execute_reply":"2024-09-19T04:13:37.812084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Pytorch dataset","metadata":{}},{"cell_type":"code","source":"class VQADataset(Dataset):\n    def __init__(\n        self,\n        data,\n        classes_to_idx,\n        img_feature_extractor,\n        text_tokenizer,\n        device,\n        root_dir='/content/val2014-resised/'\n    ):\n        self.data = data\n        self.root_dir = root_dir\n        self.classes_to_idx = classes_to_idx\n        self.img_feature_extractor = img_feature_extractor\n        self.text_tokenizer = text_tokenizer\n        self.device = device\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        img_path = os.path.join(self.root_dir, self.data[index]['image_path'])\n        img = Image.open(img_path).convert('RGB')\n        \n        if self.img_feature_extractor:\n            img = self.img_feature_extractor(images=img, return_tensors=\"pt\")\n            img = {k: v.to(self.device).squeeze(0) for k, v in img.items()}\n            \n        question = self.data[index]['question']\n        if self.text_tokenizer:\n            question = self.text_tokenizer(\n                question, \n                padding=\"max_length\", \n                max_length=20, \n                truncation=True,\n                return_tensors=\"pt\"\n            )\n            question = {k: v.to(self.device).squeeze(0) for k, v in question.items()}\n\n\n        label = self.data[index]['answer']\n        label = torch.tensor(\n            classes_to_idx[label],\n            dtype=torch.long\n        ).to(device)\n            \n        sample = {\n            'image': img,\n            'question': question,\n            'label': label\n        }\n            \n        return sample","metadata":{"execution":{"iopub.status.busy":"2024-09-19T04:13:37.813502Z","iopub.status.idle":"2024-09-19T04:13:37.813922Z","shell.execute_reply.started":"2024-09-19T04:13:37.813736Z","shell.execute_reply":"2024-09-19T04:13:37.813756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_feature_extractor = ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\ntext_tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\ntrain_dataset = VQADataset(\n    train_data,\n    classes_to_idx=classes_to_idx,\n    img_feature_extractor=img_feature_extractor,\n    text_tokenizer=text_tokenizer,\n    label_encoder=label_encoder,\n    device=device\n)\nval_dataset = VQADataset(\n    val_data,\n    classes_to_idx=classes_to_idx,\n    img_feature_extractor=img_feature_extractor,\n    text_tokenizer=text_tokenizer,\n    label_encoder=label_encoder,\n    device=device\n)\ntest_dataset = VQADataset(\n    test_data,\n    classes_to_idx=classes_to_idx,\n    img_feature_extractor=img_feature_extractor,\n    text_tokenizer=text_tokenizer,\n    label_encoder=label_encoder,\n    device=device\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T04:13:37.815457Z","iopub.status.idle":"2024-09-19T04:13:37.815896Z","shell.execute_reply.started":"2024-09-19T04:13:37.815686Z","shell.execute_reply":"2024-09-19T04:13:37.815707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_batch_size = 256\ntest_batch_size = 32\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=train_batch_size,\n    shuffle=True\n)\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=test_batch_size,\n    shuffle=False\n)\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=test_batch_size,\n    shuffle=False\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Model","metadata":{}},{"cell_type":"code","source":"class VisualEncoder(nn.Module):\n    def __init__(self):\n        super(VisualEncoder, self).__init__()\n        self.model = ViTModel.from_pretrained(\"google/vit-base-patch16-224\")\n        \n    def forward(self, inputs):\n        outputs = self.model(**inputs)\n\n        return outputs.pooler_output","metadata":{"execution":{"iopub.status.busy":"2024-09-19T04:13:49.378885Z","iopub.execute_input":"2024-09-19T04:13:49.379617Z","iopub.status.idle":"2024-09-19T04:13:49.384959Z","shell.execute_reply.started":"2024-09-19T04:13:49.379575Z","shell.execute_reply":"2024-09-19T04:13:49.383959Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class TextEncoder(nn.Module):\n    def __init__(self):\n        super(TextEncoder, self).__init__()\n        self.model = RobertaModel.from_pretrained(\"roberta-base\")\n\n    def forward(self, inputs):\n        outputs = self.model(**inputs)\n\n        return outputs.pooler_output","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Classifier(nn.Module):\n    def __init__(\n        self, \n        input_size=768*2, \n        hidden_size=512,\n        n_layers=1,\n        dropout_prob=0.2,\n        n_classes=2\n    ):\n        super(Classifier,self).__init__()\n        self.lstm = nn.LSTM(\n            input_size, \n            hidden_size, \n            num_layers=n_layers,\n            batch_first=True,\n            bidirectional=True\n        )\n        self.dropout = nn.Dropout(dropout_prob)\n        self.fc1 = nn.Linear(hidden_size*2, n_classes)\n        \n    def forward(self,x):\n        x, _ = self.lstm(x)\n        x = self.dropout(x)\n        x = self.fc1(x)\n\n        return x","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VQAModel(nn.Module):\n    def __init__(\n        self,\n        visual_encoder,\n        text_encoder,\n        classifier\n    ):\n        super(VQAModel, self).__init__()\n        self.visual_encoder = visual_encoder\n        self.text_encoder = text_encoder\n        self.classifier = classifier\n        \n\n    def forward(self, image, answer):\n        text_out = self.text_encoder(answer)\n        image_out = self.visual_encoder(image)\n        x = torch.cat((text_out, image_out), dim=1)\n        x = self.classifier(x)\n\n        return x\n\n    def freeze(self, visual=True, textual=True, clas=False):\n        if visual:\n            for n,p in self.visual_encoder.named_parameters():\n                p.requires_grad = False\n        if textual:\n            for n,p in self.text_encoder.named_parameters():\n                p.requires_grad = False\n        if clas:\n            for n,p in self.classifier.named_parameters():\n                p.requires_grad = False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_classes = len(classes)\nhidden_size = 1024\nn_layers = 1\ndropout_prob = 0.2\n\ntext_encoder = TextEncoder().to(device)\nvisual_encoder = VisualEncoder().to(device)\nclassifier = Classifier(\n    hidden_size=hidden_size,\n    n_layers=n_layers,\n    dropout_prob=dropout_prob,\n    n_classes=n_classes\n).to(device)\n\nmodel = VQAModel(\n    visual_encoder=visual_encoder,\n    text_encoder=text_encoder,\n    classifier=classifier\n).to(device)\nmodel.freeze()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = next(iter(train_loader))\n\nmodel.eval()\nwith torch.no_grad():\n    image = inputs['image']\n    question = inputs['question']\n    output = model(image, question)\n    print(output.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"def evaluate(model, dataloader, criterion):\n    model.eval()\n    correct = 0\n    total = 0\n    losses = []\n    with torch.no_grad():\n        for idx, inputs in enumerate(dataloader):\n            images = inputs['image']\n            questions = inputs['question']\n            labels = inputs['label']\n            outputs = model(images, questions)\n            loss = criterion(outputs, labels)\n            losses.append(loss.item())\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    loss = sum(losses) / len(losses)\n    acc = correct / total\n\n    return loss, acc","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit(\n    model,\n    train_loader,\n    val_loader,\n    criterion,\n    optimizer,\n    scheduler,\n    epochs\n):\n    train_losses = []\n    val_losses = []\n\n    for epoch in range(epochs):\n        batch_train_losses = []\n\n        model.train()\n        for idx, inputs in enumerate(train_loader):\n            images = inputs['image']\n            questions = inputs['question']\n            labels = inputs['label']\n\n            optimizer.zero_grad()\n            outputs = model(images, questions)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            batch_train_losses.append(loss.item())\n\n        train_loss = sum(batch_train_losses) / len(batch_train_losses)\n        train_losses.append(train_loss)\n\n        val_loss, val_acc = evaluate(\n            model, val_loader,\n            criterion\n        )\n        val_losses.append(val_loss)\n\n        print(f'EPOCH {epoch + 1}:\\tTrain loss: {train_loss:.4f}\\tVal loss: {val_loss:.4f}\\tVal Acc: {val_acc}')\n\n        scheduler.step()\n\n    return train_losses, val_losses","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = 1e-2\nepochs = 50\nscheduler_step_size = epochs * 0.6\ncriterion = nn.CrossEntropyLoss()\n\noptimizer = torch.optim.Adam(\n    model.parameters(),\n    lr=lr\n)\nscheduler = torch.optim.lr_scheduler.StepLR(\n    optimizer,\n    step_size=scheduler_step_size,\n    gamma=0.1\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_losses, val_losses = fit(\n    model,\n    train_loader,\n    val_loader,\n    criterion,\n    optimizer,\n    scheduler,\n    epochs\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(12, 5))\nax[0].plot(train_losses)\nax[0].set_title('Training Loss')\nax[0].set_xlabel('Epoch')\nax[0].set_ylabel('Loss')\nax[1].plot(val_losses, color='orange')\nax[1].set_title('Val Loss')\nax[1].set_xlabel('Epoch')\nax[1].set_ylabel('Loss')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"val_loss, val_acc = evaluate(\n    model,\n    val_loader,\n    criterion\n)\ntest_loss, test_acc = evaluate(\n    model,\n    test_loader,\n    criterion\n)\n\nprint('Evaluation on val/test dataset')\nprint('Val accuracy: ', val_acc)\nprint('Test accuracy: ', test_acc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}